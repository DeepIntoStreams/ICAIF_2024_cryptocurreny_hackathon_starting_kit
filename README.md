# Starting kit for ICAIF 2024 competition: Crypto Market Simulation for Risk Estimation

Welcome to our ICAIF 2024 competition: Crypto Market Simulation for Risk Estimation Starter Kit repository. This repository provides a standard pipeline to help you with the kick-off of our hackathon. For more details about the hackathon, visit the [Hackathon Website](https://hackathon.deepintomlf.ai/competitions/40). 

In this pipeline, we include: 
1) data importing,
2) the model build-up for both the generator and discriminator,
3) training algorithm design,
4) offline evaluation module.

## Environment Setup
The code has been tested successfully using Python 3.8 and pytorch 1.11.0. A typical process for installing the package dependencies involves creating a new Python virtual environment.

To install the required packages, run the following:
```console
conda install pytorch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0 cudatoolkit=10.2 -c pytorch
pip install cupy-cuda102
pip install -r requirements.txt
```

For code illustration, please refer to the Jupyter Notebook we created, namely, example_pipeline.ipynb.

## Data
For this challenge, the training data is located at [data/](data/). Here, we provide two different datasets, both of which are numpy arrays saved in `.pkl` format. The first dataset
[data/ref_log_return.pkl](data/) includes `8937` sample paths. Each sample consists of the hourly log returns of 3 representative cryptocurrencies. Each time series has length 24, corresponding to the process over a day. The dataset has shape [8937, 24, 3]. The second dataset [data/ref_price.pkl](data/) consists of the initial prices of 3 representative cryptocurrencies. The dataset has shape [8937, 1, 3].
In order to convert log-return process to price process, use the function `log_return_to_price()` from [src/evaluation/strategies.py](src/evaluation/strategies.py).

## Sample submission
We also provide a sample submission bundle at [sample_submission_bundle](sample_submission_bundle/) which includes: 
1) `model_dict.pkl`: Dictionary of model parameters used to generate the samples.
2) `model.py`: Script of your model architecture, model loading, and data generation. We recommend participants build the model as a subclass of `torch.nn.Module`. However, models from other deep learning engines are also welcome. The file must contain a function named `init_generator()`, which initializes an instance of the generator and loads the model parameter from `model_dict.pkl`, returning the trained model. The forward function of the loaded model takes as input:
 
    - `batch_size`: integer. The number of paths to be generated.
    - `device`: string, either 'cpu' or 'cuda', the model should support data generation on both devices.
      The returning object should be a tensor of the shape [`batch_size`, 24, 3].
3) `fake_log_return.pkl`: Fake log-return process generated by the trained model. The array must have the shape [1800, 24, 3] and can be converted into a torch tensor via `torch.tensor()`.

Finally, we wish you good luck during the competition and most importantly, have fun!!!
